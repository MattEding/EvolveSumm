{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import contextlib\n",
    "import itertools\n",
    "import importlib\n",
    "import functools\n",
    "import io\n",
    "import math\n",
    "import operator\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk.tokenize\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.stats import wasserstein_distance as earth_movers_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as str_io, contextlib.redirect_stdout(str_io):\n",
    "    import this\n",
    "    zen = str_io.getvalue()\n",
    "\n",
    "del str_io, this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(text):\n",
    "    no_punctuation = ''.join(t for t in text if t not in string.punctuation)\n",
    "    return frozenset(nltk.tokenize.word_tokenize(no_punctuation))\n",
    "\n",
    "text = zen.lower()\n",
    "\n",
    "D = document_sentences = set(nltk.tokenize.sent_tokenize(text))\n",
    "T = document_distinct_words = distinct_words(text)\n",
    "S = sentence_distinct_words = {distinct_words(ds) for ds in document_sentences}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Google Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: double check scientific paper's handling of bad log values\n",
    "def norm_google_distance(t_k, t_l, D, S):\n",
    "    \"\"\"Metric for distance between two terms-- tₖ, tₗ\"\"\"\n",
    "    \n",
    "    f_k = sum(t_k in sent for sent in S)\n",
    "    f_l = sum(t_l in sent for sent in S)\n",
    "    if not (f_k and f_l):\n",
    "        raise ValueError('terms must be in document')\n",
    "    \n",
    "    f_kl = sum((t_k in sent) and (t_l in sent) for sent in S)\n",
    "    if (f_k > 0) and (f_l > 0) and (f_kl == 0):\n",
    "        return 1.0\n",
    "    \n",
    "    log_kl = (math.log(f_k), math.log(f_l))\n",
    "    n = len(D)\n",
    "    \n",
    "    numerator = max(log_kl) - math.log(f_kl)\n",
    "    denominator = math.log(n) - min(log_kl)\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def norm_google_similarity_term(t_k, t_l, D, S):\n",
    "    \"\"\"Metric for similarity between two terms-- tₖ, tₗ\"\"\"\n",
    "    \n",
    "    ngd = normalized_google_distance(t_k, t_l, D, S)\n",
    "    return math.exp(-ngd)\n",
    "\n",
    "\n",
    "def norm_google_similarity_sent(S_i, S_j, D, S):\n",
    "    total = sum(sum(norm_google_similarity_term(t_k, t_l, D, S) for t_l in S_j) for t_k in S_i)\n",
    "    return total / len(S_i) / len(S_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tₖ == tₗ --> 1\n",
    "assert norm_google_similarity_term('python', 'python', D, S) == 1\n",
    "\n",
    "# if (tₖ != tₗ) and (fₖ == fₗ == fₖₗ > 0) --> 1\n",
    "assert norm_google_similarity_term('explicit', 'implicit', D, S) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c1caea7fa9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mC_i\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mC_j\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mC_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# assert not functools.reduce(operator.and_, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C = k_clusters = {frozenset(), ...}\n",
    "#: 1) Two different clusters should have no sentences in common\n",
    "# assert all(not C_i & C_j for C_i, C_j in itertools.combinations(C, C))\n",
    "\n",
    "#: 2) Each sentence should definitely be attached to a cluster\n",
    "# assert functools.reduce(operator.or_, C) == D\n",
    "\n",
    "#: 3) Each cluster should have at least one sentence assigned\n",
    "# assert all(C_p for C_p in C)\n",
    "\n",
    "\n",
    "#: want to maximize\n",
    "def F(C):\n",
    "    return pow(1 + sigmoid(F_1(C)), F_2(C))\n",
    "\n",
    "\n",
    "#: want to maximize\n",
    "def F_1(C):\n",
    "    outer = 0\n",
    "    for C_p in C:\n",
    "        inner = 0\n",
    "        for S_i, S_j in itertools.combinations(C_p):\n",
    "            sim_ngd = norm_google_similarity_sent(S_i, S_i, D, S)           # D, S args\n",
    "            inner += sim_ngd\n",
    "        outer += len(C_p) * inner\n",
    "    return outer\n",
    "\n",
    "\n",
    "#: want to minimize\n",
    "def F_2(C):\n",
    "    C = tuple(C)    # may need to use 'ordered sets'\n",
    "    k = len(C)\n",
    "    \n",
    "    sum_0 = 0\n",
    "    for p in range(k - 1):\n",
    "        sum_1 = 0\n",
    "        for q in range(p + 1, k):\n",
    "            sum_2 = 0\n",
    "            for S_i in C[p]:\n",
    "                sum_3 = 0\n",
    "                for S_j in C[q]:\n",
    "                    sum_3 += sum(norm_google_similarity_sent(S_i, S_j))\n",
    "                sum_2 += sum_3\n",
    "            sum_1 += sum_2 / len(C[q])\n",
    "        sum_0 += sum_1 / len(C[p])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(zen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
