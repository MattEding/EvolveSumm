{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import operator\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.stats import wasserstein_distance as earth_movers_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "with io.StringIO() as str_io, contextlib.redirect_stdout(str_io):\n",
    "    import this\n",
    "    zen = str_io.getvalue()\n",
    "\n",
    "del str_io, this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Algorithm for Extractive Text Summarization\n",
    "https://www.researchgate.net/profile/Ramiz_Aliguliyev/publication/220518077_Evolutionary_Algorithm_for_Extractive_Text_Summarization/links/09e4151356fc2caab6000000.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(text):\n",
    "    no_punctuation = ''.join(t for t in text if t not in string.punctuation)\n",
    "    return frozenset(tokenize.word_tokenize(no_punctuation))\n",
    "\n",
    "text = zen.lower()\n",
    "\n",
    "D = document_sentences = set(tokenize.sent_tokenize(text))\n",
    "T = document_distinct_words = distinct_words(text)\n",
    "S = sentence_distinct_words = {distinct_words(ds) for ds in document_sentences}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Google Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/normalized_google_distance.png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (2) -- double check scientific paper's handling of \"bad\" log values\n",
    "def norm_google_distance(t_k, t_l, D, S):\n",
    "    \"\"\"Metric for distance between two terms-- tₖ, tₗ\"\"\"\n",
    "    \n",
    "    f_k = sum(t_k in sent for sent in S)\n",
    "    f_l = sum(t_l in sent for sent in S)\n",
    "    if not (f_k and f_l):\n",
    "        raise ValueError('terms must be in document')\n",
    "    \n",
    "    f_kl = sum((t_k in sent) and (t_l in sent) for sent in S)\n",
    "    if (f_k > 0) and (f_l > 0) and (f_kl == 0):\n",
    "        return 1.0\n",
    "    \n",
    "    log_kl = (math.log(f_k), math.log(f_l))\n",
    "    n = len(D)\n",
    "    \n",
    "    numerator = max(log_kl) - math.log(f_kl)\n",
    "    denominator = math.log(n) - min(log_kl)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/sim_ngd_terms.png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (1)\n",
    "def norm_google_similarity_term(t_k, t_l, D, S):\n",
    "    \"\"\"Metric for similarity between two terms-- tₖ, tₗ\"\"\"\n",
    "    \n",
    "    ngd = normalized_google_distance(t_k, t_l, D, S)\n",
    "    return math.exp(-ngd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/sim_ngd_sentences.png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (3)\n",
    "def norm_google_similarity_sent(S_i, S_j, D, S):\n",
    "    total = sum(sum(norm_google_similarity_term(t_k, t_l, D, S) for t_l in S_j) for t_k in S_i)\n",
    "    return total / len(S_i) / len(S_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tₖ == tₗ --> 1\n",
    "assert norm_google_similarity_term('python', 'python', D, S) == 1\n",
    "\n",
    "# if (tₖ != tₗ) and (fₖ == fₗ == fₖₗ > 0) --> 1\n",
    "assert norm_google_similarity_term('explicit', 'implicit', D, S) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = k_clusters = {frozenset(), ...}\n",
    "#: 1) Two different clusters should have no sentences in common\n",
    "# assert all(not C_i & C_j for C_i, C_j in itertools.combinations(C, C))\n",
    "\n",
    "#: 2) Each sentence should definitely be attached to a cluster\n",
    "# assert functools.reduce(operator.or_, C) == D\n",
    "\n",
    "#: 3) Each cluster should have at least one sentence assigned\n",
    "# assert all(C_p for C_p in C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/f.png\" alt=\"inverse operator psuedo-code\" width=\"50%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (4) -- want to maximize\n",
    "def F(C):\n",
    "    return pow(1 + sigmoid(F_1(C)), F_2(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/f1.png\" alt=\"inverse operator psuedo-code\" width=\"50%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (5) -- want to maximize\n",
    "def F_1(C):\n",
    "    outer = 0\n",
    "    for C_p in C:\n",
    "        inner = 0\n",
    "        for S_i, S_j in itertools.combinations(C_p):\n",
    "            sim_ngd = norm_google_similarity_sent(S_i, S_i, D, S)           # D, S args\n",
    "            inner += sim_ngd\n",
    "        outer += len(C_p) * inner\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/f2.png\" alt=\"inverse operator psuedo-code\" width=\"50%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (6) -- want to minimize\n",
    "def F_2(C):\n",
    "    C = tuple(C)    # may need to use 'ordered sets'; unclear how to handle p = 1 to k-1\n",
    "    k = len(C)\n",
    "    \n",
    "    sum_0 = 0\n",
    "    for p in range(k - 1):\n",
    "        sum_1 = 0\n",
    "        for q in range(p + 1, k):\n",
    "            sum_2 = 0\n",
    "            for S_i in C[p]:\n",
    "                sum_3 = 0\n",
    "                for S_j in C[q]:\n",
    "                    sum_3 += sum(norm_google_similarity_sent(S_i, S_j))\n",
    "                sum_2 += sum_3\n",
    "            sum_1 += sum_2 / len(C[q])\n",
    "        sum_0 += sum_1 / len(C[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None  # need reproducibility option\n",
    "\n",
    "N = len(population)\n",
    "n = len(sentences)\n",
    "k = len(clusters)\n",
    "\n",
    "r = range(N)\n",
    "s = range(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_r(t):\n",
    "    return [x_r_1(t), x_r_2(t),..., x_r_n(t)]\n",
    "\n",
    "def x_r_s(t):\n",
    "    return integer in range(k)\n",
    "\n",
    "def Y_r(t):\n",
    "    return [y_r_1(t), y_r_2(t),..., y_r_n(t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/y_r_s(t+1).png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (7) -- crossover_rate is CR in paper\n",
    "def y_r_s(t, lam, crossover_rate):\n",
    "    x_r1_s = random.choice(...)\n",
    "    x_r2_s = random.choice(...)\n",
    "    x_r3_s = random.choice(...)\n",
    "    \n",
    "    rand_s = random.random(0, 1)\n",
    "    if rand_s < crossover_rate:\n",
    "        return x_r1_s(t-1) + lam * (x_r2_s(t-1) - x_r3_s(t-1))\n",
    "    else:\n",
    "        return x_r_s(t-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/pngs/X_r(t+1).png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (8)\n",
    "def X_r(t, f):\n",
    "    y = y_r(t-1)\n",
    "    x = x_r(t-1)\n",
    "    if f(y) > f(x):\n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness\n",
    "<img src=\"./data/pngs/fitness.png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (9)\n",
    "def fitness_1(X_a):\n",
    "    return F_1(X_a)\n",
    "\n",
    "#: (10)\n",
    "def fitness_2(X_a):\n",
    "    return 1 / F_2(X_a)\n",
    "\n",
    "#: (11)\n",
    "def fitness(X_a):\n",
    "    return F(X_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation\n",
    "<img src=\"./data/pngs/m_r_s(t+1).png\" alt=\"inverse operator psuedo-code\" width=\"75%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (12)\n",
    "def m_r_s(t):\n",
    "    # do I need same rand_s from (7)?\n",
    "    rand_s = random.uniform(0, 1)\n",
    "    sigm = sigmoid(y_r_s(t))\n",
    "    return rand_s < sigm\n",
    "\n",
    "# need mutation_rate parameter (MR in paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 - Psuedo-code\n",
    "<img src=\"./data/pngs/fig1_-_inversion_operator_psuedo_code.png\" alt=\"inverse operator psuedo-code\" width=\"50%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversion_operator(X_r, m_r_p1):\n",
    "    X_r_p1 = [None] * len(X_r)\n",
    "    S = set()\n",
    "    \n",
    "    for i, (x, m) in enumerate(zip(X_r, m_r_p1)):\n",
    "        if m == 1:\n",
    "            X_r_p1[i] = x\n",
    "        else:\n",
    "            S.add(i)\n",
    "    \n",
    "    while len(S) > 0:\n",
    "        s_min, s_max = min(S), max(S)\n",
    "        X_r_p1[s_min] = X_r[s_max]\n",
    "        X_r_p1[s_max] = X_r[s_min]\n",
    "        S -= {s_max, s_min}\n",
    "    \n",
    "    return X_r_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2 - Example\n",
    "<img src=\"./data/pngs/fig2_-_inversion_operator_diagram.png\" alt=\"inverse operator example\" width=\"50%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = [3, 2, 4, 2, 3, 1, 4, 1]\n",
    "m_r_p1 = [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "X_r_p1 = [4, 2, 4, 1, 3, 2, 3, 1]\n",
    "\n",
    "assert inversion_operator(X_r, m_r_p1) == X_r_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE-N\n",
    "(Recall Oriented Understudy for Gisting Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: (14)\n",
    "def rouge_n(n, y_pred, y_true):\n",
    "    n_gram_pred = set(ngrams(y_pred, n))\n",
    "    n_gram_true = set(ngrams(y_true, n))\n",
    "    return len(n_gram_pred & n_gram_true) / len(n_gram_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = 'police killed the gunman'\n",
    "S2 = 'police kill the gunman'\n",
    "S3 = 'the gunman kill police'\n",
    "\n",
    "rouge_n(2, S2, S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Steps:  \n",
    " - stop words\n",
    " - lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = 'a good diet must have apples and bananas'.split()\n",
    "y_pred = 'apples and bananas are must for a good diet'.split()\n",
    "\n",
    "n = 2\n",
    "n_gram_pred = set(ngrams(y_pred, n))\n",
    "n_gram_true = set(ngrams(y_true, n))\n",
    "\n",
    "rouge = len(n_gram_pred & n_gram_true) / len(n_gram_true)\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
