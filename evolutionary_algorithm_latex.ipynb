{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "# import multiprocessing\n",
    "import operator\n",
    "import string\n",
    "# import random\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# from scipy.spatial.distance import jaccard\n",
    "# from scipy.special import expit as sigmoid\n",
    "\n",
    "# from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Algorithms\n",
    "- [Discrete Differential Evolution for Text Summarization](https://www.researchgate.net/publication/281662415_Discrete_Differential_Evolution_for_Text_Summarization)\n",
    "- [Evolutionary Algorithm for Extractive Text Summarization](https://www.researchgate.net/profile/Ramiz_Aliguliyev/publication/220518077_Evolutionary_Algorithm_for_Extractive_Text_Summarization/links/09e4151356fc2caab6000000.pdf)\n",
    "- [An Improved Evolutionary Algorithm for Extractive Text Summarization](https://link.springer.com/chapter/10.1007/978-3-642-36543-0_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Coefficient Similarity Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "sim_{ jaccard } ( S_i, S_j ) = \n",
    "\\dfrac\n",
    "    { | S_i \\cap S_j | }\n",
    "    { | S_i \\cup S_j | }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def jaccard_similarity(a, b):\n",
    "    #: assume union is non-empty since each sentence >= 1 word\n",
    "    return np.sum(a & b) / np.sum(a | b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ C $ be a partition of $ D $ with $ k $ clusters.  \n",
    "$ C = \\{ C_1, C_2, ..., C_k \\} $  \n",
    "\n",
    "where:\n",
    "- $ C_p \\cap C_q = \\emptyset, \n",
    "        \\forall p \\ne q \\in \\{ 1, 2, ..., k \\} \n",
    "  $\n",
    "- $ \\bigcup\\limits\n",
    "    _{ p = 1 }\n",
    "    ^k C_p = D \n",
    "  $\n",
    "- $ C_p \\ne \\emptyset, \n",
    "        \\forall p \\in \\{ 1, 2, ..., k \\}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "$\n",
    "\\large\n",
    "sigm ( x ) = \n",
    "\\dfrac\n",
    "    { 1 }\n",
    "    { 1 + \\text{exp} ( -x ) }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53014511c14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numba' is not defined"
     ]
    }
   ],
   "source": [
    "@numba.njit\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-Cluster Similiarity (Cohesion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F_1 = \n",
    "\\sum\\limits\n",
    "    _{ \\small p = 1 }\n",
    "    ^{ \\small k } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_i, S_j \\in C_p } \n",
    "\\dfrac \n",
    "    { sim ( S_i, S_j ) } \n",
    "    { | C_p | } \n",
    "\\rightarrow \\text{max}\n",
    "$\n",
    "\n",
    "*(__Note:__ Evol Alg for Ext Txt Summ doesn't show division of $|C_p|$ but I believe this to be a typo since the paragraph detailing it says \"the average sum\". Additionally the Disc Diff Evol for Txt Summ shows it as such.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def cohesion(chromosome, similarity, document):\n",
    "    total = 0\n",
    "    for p in np.unique(chromosome):\n",
    "        sents = document[np.where(chromosome == p)]\n",
    "        k = len(sents)\n",
    "        #: combinations choose 2\n",
    "        for i in range(k-1):\n",
    "            for j in range(i+1, k):\n",
    "                total += similarity(sents[i], sents[j]) / len(sents)  \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Cluster Dissimilarity (Separation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F_2 = \n",
    "\\sum\\limits\n",
    "    _{ \\small p = 1 }\n",
    "    ^{ \\small k - 1 }\n",
    "\\sum\\limits\n",
    "    _{ \\small q = p + 1 }\n",
    "    ^{ \\small k } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_i \\in C_p } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_j \\in C_q } \n",
    "\\dfrac \n",
    "    { sim ( S_i, S_j ) } \n",
    "    { | C_p | \\cdot | C_q | }\n",
    "\\rightarrow \\text{min}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def separation(chromosome, similarity, document):\n",
    "    total = 0\n",
    "    k = len(np.unique(chromosome))\n",
    "    #: combinations choose 2\n",
    "    for p in range(k-1):\n",
    "        for q in range(p+1, k):\n",
    "            sents_p = document[np.where(chromosome == p)]\n",
    "            sents_q = document[np.where(chromosome == q)]\n",
    "            #: product\n",
    "            m, n = len(sents_p), len(sents_q)\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    total += similarity(sents_p[i], sents_q[j]) / m / n\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter/Intra-Cluster Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F = \\big( 1 + sigm ( F_1 ) \\big)\n",
    "    ^{ F_2 } \\rightarrow \\text{max}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def cohesion_separation(chromosome, similarity, document):\n",
    "    coh = cohesion(chromosome, similarity, document)\n",
    "    sep = separation(chromosome, similarity, document)\n",
    "    return (1 + sigmoid(coh)) ** sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "fitness_1 \\big( X_a ( t ) \\big) = F_1 \\big( X_a ( t ) \\big)\n",
    "$\n",
    "\n",
    "$\n",
    "\\large\n",
    "fitness_2 \\big( X_a ( t ) \\big) = \\dfrac{ 1 }{ F_2 ( X_a ( t ) ) }\n",
    "$\n",
    "\n",
    "$\n",
    "\\large\n",
    "fitness \\big( X_a ( t ) \\big) = F \\big( X_a ( t ) \\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Discrete Differential Evolution Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the population with $ N $ chromosomes each composed of $ n $ random integers from \\[1, k\\].  \n",
    "\n",
    "$\n",
    "X_r ( t ) = [ x_{ r, 1 } ( t ), x_{ r, 2 } ( t ), ..., x_{ r, n } ( t ) ]\n",
    "$  \n",
    "\n",
    "where:\n",
    "- $ x_{ r, s } ( t ) \\in \\{ 1, 2, ..., k \\} $\n",
    "- $ r = 1, 2, ..., N $\n",
    "- $ s = 1, 2, ..., n $\n",
    "- $ N $ is the population size\n",
    "- $ n $ is the number of sentences _(in the document)_\n",
    "- $ k $ is the number of clusters _(number of sentences for summary)_\n",
    "- $ t $ is the iteration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_chromosome(choices, length):\n",
    "    chrom = np.full(length, -1)\n",
    "    #: ensure that each choice is accounted for at least once\n",
    "    idxs = np.random.choice(np.arange(length), len(choices), replace=False)\n",
    "    chrom[idxs] = np.random.permutation(choices)\n",
    "    idxs = np.where(chrom == -1)[0]\n",
    "    chrom[idxs] = np.random.choice(choices, len(idxs))\n",
    "    return chrom\n",
    "\n",
    "\n",
    "def init_population(population_size, cluster_amount, chromosome_length):\n",
    "    clusts = np.arange(cluster_amount)\n",
    "    chroms = [init_chromosome(clusts, chromosome_length) for _ in range(population_size)]\n",
    "    pop = np.vstack(chroms)\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "y_{ r, s } ( t + 1 ) = \n",
    "\\begin{cases}\n",
    "    x_{ r1, s } ( t ) + \\lambda \\big( x_{ r2, s } ( t ) - x_{ r3, s } ( t ) \\big) \n",
    "        & \\text{if } rand_s < \\text{CR} \\\\\n",
    "    x_{ r, s } ( t ) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where  \n",
    "- For each $ X_r $, randomly sample $ X_{ r1 } ( t ), X_{ r2 } ( t ), X_{ r3 } ( t ) $ \n",
    "  from the same generation _(each distinct)_\n",
    "- $ rand_s $ is uniformally distributed random numbers from $ [ 0, 1 ] $ \n",
    "  chosen once for each $ s \\in \\{ 1, 2, ..., n \\} $\n",
    "\n",
    "hyper-parameters \n",
    "- $ \\lambda $ is a scale factor from $ [ 0, 1 ] $\n",
    "- $ \\text{CR} $ is the crossover rate from $ [ 0, 1 ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offspring(population, randoms, lambda_, crossover_rate):\n",
    "    #: For computation time, relax requirement that X_r, X_r1, X_r2, X_r3 are distinct. \n",
    "    #: With large population size, this is unlikely to occur, and if it does, it doesn't\n",
    "    #: seem that detrimental. Also is this mitigated with appropriate lam choice?\n",
    "    n = len(population)\n",
    "    idxs = np.random.choice(np.arange(n), size=(n, 3))\n",
    "    chrom_1, chrom_2, chrom_3 = map(np.squeeze, np.split(population[idxs], 3, axis=1))\n",
    "    k = len(np.unique(population))\n",
    "    offspr = (chrom_1 + lambda_ * (chrom_2 - chrom_3)) % k\n",
    "    mask = randoms < crossover_rate\n",
    "    offspr[mask] = population[mask]\n",
    "    return offspr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "X_r(t+1) = \n",
    "\\begin{cases}\n",
    "    Y_r ( t + 1 ) & \\text{if } f \\big( Y_r ( t + 1 ) \\big) > f \\big( X_r ( t ) \\big) \\\\\n",
    "    X_r ( t ) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where \n",
    "- $ f ( \\cdot ) $ is the objective function to be maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_generation(population, offspring, func):\n",
    "    fit_off = np.array([func(chrom) for chrom in offspring])\n",
    "    fit_pop = np.array([func(chrom) for chrom in population])\n",
    "    mask = fit_off > fit_pop\n",
    "    population[mask] = offspring[mask]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each iteration $ t + 1 $ for each $ X_r ( t ) $ creates\n",
    "$ m_r ( t + 1 ) = [ m_{ r, 1 } ( t ), m_{ r, 2 } ( t ), ..., m_{ r, n } ( t ) ] $.  \n",
    "For each gene, 1 indicates no mutation and 0 means mutate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "m_{ r, s } ( t + 1 ) = \n",
    "\\begin{cases}\n",
    "    1 & \\text{if } rand_s < sigm \\big( y_{ r, s } ( t + 1 ) \\big) \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversion Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 - Psuedo-code\n",
    "<img src=\"./data/pngs/fig1_-_inversion_operator_psuedo_code.png\" alt=\"Fig 1. Inverse operator psuedo-code\" width=\"33%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2 - Example\n",
    "<img src=\"./data/pngs/fig2_-_inversion_operator_diagram.png\" alt=\"Fig 2. Inverse operator example\" width=\"33%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(population, randoms):\n",
    "    mask = randoms < sigmoid(population)\n",
    "    #: inversion operator\n",
    "    idxs = np.nonzero(mask)\n",
    "    arr = np.array(idxs)\n",
    "    sorter = np.lexsort((-arr[1], arr[0]))\n",
    "    rev = arr.T[sorter].T\n",
    "    population[idxs] = population[(rev[0], rev[1])]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pertinent Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: early stopping --> little fitness improvement over x generations, good enough fitness score\n",
    "def run_iterations(pop_size, summ_len, num_sents, func, lam, cr, iterations, *, mutate_after=True,\n",
    "                   seed=None, verbose=False, save_rate=np.nan, save_dir=None):\n",
    "    \n",
    "    if save_dir is not None:\n",
    "        save_dir = pathlib.Path(save_dir)\n",
    "        if not save_dir.is_dir():\n",
    "            msg = f'save_dir={save_dir} not a valid directory path'.format(save_dir=save_dir)\n",
    "            raise NotADirectoryError(msg)\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    pop = init_population(pop_size, summ_len, num_sents)\n",
    "    shape = pop.shape\n",
    "    for i in range(iterations):\n",
    "        if i % save_rate == 0:\n",
    "            file = save_dir / 'generation_{i:0>pad}'.format(i=i, pad=len(str(iterations)))\n",
    "            np.save(file, pop)\n",
    "            \n",
    "        if verbose:\n",
    "            print(i)  #TODO: logfile --> iteration number, best fitness score, avg fitness score, hyper-params\n",
    "        \n",
    "        rand = np.random.random_sample(shape)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        offspr = get_offspring(pop, rand, lam, cr)\n",
    "        t1 = time.time()\n",
    "        PROFILER['offspring'] += t1 - t0\n",
    "        \n",
    "        #: option since papers unclear if mutate at offspring or survivors stage\n",
    "        if not mutate_after:\n",
    "            mutate(offspr, rand)\n",
    "            \n",
    "        t0 = time.time()\n",
    "        next_generation(pop, offspr, func)\n",
    "        t1 = time.time()\n",
    "        PROFILER['generation'] += t1 - t0\n",
    "        \n",
    "        if mutate_after:\n",
    "            t0 = time.time()\n",
    "            mutate(pop, rand)\n",
    "            t1 = time.time()\n",
    "            PROFILER['mutate'] += t1 - t0\n",
    "    \n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_chromosome(population):\n",
    "    #TODO: make sure it picks one with all k-clusters\n",
    "    fits = np.argmax([fitness(chrom) for chrom in population])\n",
    "    chrom = population[fits]\n",
    "    return chrom\n",
    "    \n",
    "\n",
    "def central_sentences(chromosome, document, metric=cosine_distances):\n",
    "    central_sents = []\n",
    "    for cluster in np.unique(chromosome):\n",
    "        idxs = np.where(chromosome == cluster)[0]\n",
    "        sents = document[idxs]\n",
    "        centroid = sents.mean(axis=0)[np.newaxis,:]\n",
    "        dists = metric(sents, centroid)\n",
    "        cent_sent = idxs[np.argmin(dists)]\n",
    "        central_sents.append(cent_sent)\n",
    "    return sorted(central_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-N\n",
    "_(Recall Oriented Understudy for Gisting Evaluation)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "\\text{ROUGE-N} = \n",
    "\\dfrac\n",
    "    { \\sum \\limits\n",
    "        _{ \\small S \\in Summ_{ ref }} \n",
    "        \\sum \\limits\n",
    "        _{ \\small \\text{N-gram} \\in S } \n",
    "            Count_{ \\small match } ( \\text{N-gram} ) }\n",
    "    { \\sum \\limits\n",
    "        _{ \\small S \\in Summ_{ ref } } \n",
    "        \\sum \\limits\n",
    "            _{ \\small \\text{N-gram} \\in S } \n",
    "            Count( \\text{N-gram} ) }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(n, y_pred, y_true):\n",
    "    n_gram_pred = set(ngrams(y_pred, n))\n",
    "    n_gram_true = set(ngrams(y_true, n))\n",
    "    return len(n_gram_pred & n_gram_true) / len(n_gram_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "data = cwd / 'data'\n",
    "jsons = data / 'jsons'\n",
    "json_2018 = jsons / '2018' / '2018.json'\n",
    "\n",
    "with open(json_2018) as fp:\n",
    "    articles_2018 = json.load(fp)['2018']\n",
    "\n",
    "article = articles_2018[67]\n",
    "text = article['story']\n",
    "summ_true = article['summary']\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.156807899475098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'offspring': 0.16056060791015625,\n",
       "         'generation': 12.841875314712524,\n",
       "         'mutate': 0.12311697006225586})"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "PROFILER = collections.Counter()\n",
    "\n",
    "\n",
    "def fitness(chromosome):\n",
    "    return cohesion_separation(chromosome, jaccard_similarity, doc)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "sents_lower = tokenize.sent_tokenize(text.lower())\n",
    "vec = cv.fit_transform(sents_lower)\n",
    "doc = vec.toarray().astype(bool).astype(int)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "pop = run_iterations(pop_size=100, summ_len=5, num_sents=len(doc), \n",
    "                     func=fitness, lam=0.9, cr=0.5, iterations=1000, verbose=False, seed=0)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "\n",
    "\n",
    "chrom_best = best_chromosome(pop)\n",
    "idxs = central_sentences(chrom_best, doc)\n",
    "#: 2018 article[999] -- gay skier winter olympics -> no lower() causes wierd sentence breaks that throw off summary\n",
    "# sents_norm = tokenize.sent_tokenize(text)\n",
    "summ_evol = '\\n'.join(np.array(sents_lower)[idxs])\n",
    "\n",
    "PROFILER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated at 8:55 p.m. et\n",
      "\n",
      "police in sussex, england, say they have made two arrests in the disruption of flights because of drone sightings at busy gatwick, the u.k.'s second-largest airport.\n",
      "airport officials had been confident enough that the skies and runways were safe to resume service after a drone sighting on friday morning.\n",
      "airfield movements were suspended while we investigated this as safety remains our main priority,\" airport officials said on twitter, just an hour after announcing the friday morning shutdown.\n",
      "that interruption was significantly shorter than one that began wednesday night, when reports of unmanned aircraft nearby triggered a day and a half of suspended flights.\n",
      "drones were first spotted in the vicinity on wednesday night, idling planes on the tarmac as officials sought to ensure the airspace was safe for takeoff.\n"
     ]
    }
   ],
   "source": [
    "print(summ_evol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(n, y_pred):\n",
    "    for i in range(1, n+1):\n",
    "        score = rouge_n(i, y_pred, summ_true)\n",
    "        print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolutionary\n",
      "1 0.8333333333333334\n",
      "2 0.8347107438016529\n",
      "3 0.5764705882352941\n"
     ]
    }
   ],
   "source": [
    "print('evolutionary')\n",
    "scores(3, summ_evol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim\n",
      "1 0.7333333333333333\n",
      "2 0.6033057851239669\n",
      "3 0.3058823529411765\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "summ_gensim = gensim.summarization.summarize(text)\n",
    "print('gensim')\n",
    "scores(3, summ_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport officials had been confident enough that the skies and runways were safe to resume service after a drone sighting on Friday morning.\n",
      "Airfield movements were suspended while we investigated this as safety remains our main priority,\" airport officials said on Twitter, just an hour after announcing the Friday morning shutdown.\n"
     ]
    }
   ],
   "source": [
    "print(summ_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumy - text rank\n",
      "1 0.9666666666666667\n",
      "2 0.859504132231405\n",
      "3 0.5941176470588235\n",
      "\n",
      "sumy - lex rank\n",
      "1 0.8666666666666667\n",
      "2 0.768595041322314\n",
      "3 0.48823529411764705\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "def format_sumy(sumy_summary):\n",
    "    return ''.join(char for sent in sumy_summary for char in str(sent) if char in string.printable)\n",
    "\n",
    "parser = PlaintextParser(text, Tokenizer('english'))\n",
    "\n",
    "text_rank = TextRankSummarizer()\n",
    "summ_text_rank = format_sumy(text_rank(parser.document, 5))\n",
    "print('sumy - text rank')\n",
    "scores(3, summ_text_rank)\n",
    "\n",
    "print()\n",
    "\n",
    "lex_rank = LexRankSummarizer()\n",
    "summ_lex_rank = format_sumy(lex_rank(parser.document, 5))\n",
    "print('sumy - lex rank')\n",
    "scores(3, summ_lex_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police in Sussex, England, say they have made two arrests in the disruption of flights because of drone sightings at busy Gatwick, the U.K.'s second-largest airport.Police on Friday night said their investigations are ongoing and reiterated their call for members of the public to report anything they know about the drone operators.Airport officials had been confident enough that the skies and runways were safe to resume service after a drone sighting on Friday morning.At least one frustrated tweeter seemed to speak eloquently for the more than 100,000 people who have had their plans disrupted at the U.K.'s second-busiest airport: \"Oh, come on!\"Drones were first spotted in the vicinity on Wednesday night, idling planes on the tarmac as officials sought to ensure the airspace was safe for takeoff.\n"
     ]
    }
   ],
   "source": [
    "print(summ_text_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETFlights had already resumed on Friday, after suspensions starting Wednesday night and a complete shutdown on Thursday night, leaving weary travelers longing for their holiday destinations.Airport officials had been confident enough that the skies and runways were safe to resume service after a drone sighting on Friday morning.\"Flights have now resumed.At least one frustrated tweeter seemed to speak eloquently for the more than 100,000 people who have had their plans disrupted at the U.K.'s second-busiest airport: \"Oh, come on!\"\n"
     ]
    }
   ],
   "source": [
    "print(summ_lex_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 8:55 p.m. ET\n",
      "\n",
      "Police in Sussex, England, say they have made two arrests in the disruption of flights because of drone sightings at busy Gatwick, the U.K.'s second-largest airport.\n",
      "\n",
      "Flights had already resumed on Friday, after suspensions starting Wednesday night and a complete shutdown on Thursday night, leaving weary travelers longing for their holiday destinations.\n",
      "\n",
      "Police on Friday night said their investigations are ongoing and reiterated their call for members of the public to report anything they know about the drone operators.\n",
      "\n",
      "Airport officials had been confident enough that the skies and runways were safe to resume service after a drone sighting on Friday morning. \"Flights have now resumed. Airfield movements were suspended while we investigated this as safety remains our main priority,\" airport officials said on Twitter, just an hour after announcing the Friday morning shutdown.\n",
      "\n",
      "That interruption was significantly shorter than one that began Wednesday night, when reports of unmanned aircraft nearby triggered a day and a half of suspended flights. But when the announcement came down midday Friday, just hours after those flights had resumed, travelers understandably braced for the worst.\n",
      "\n",
      "At least one frustrated tweeter seemed to speak eloquently for the more than 100,000 people who have had their plans disrupted at the U.K.'s second-busiest airport: \"Oh, come on!\"\n",
      "\n",
      "Drones were first spotted in the vicinity on Wednesday night, idling planes on the tarmac as officials sought to ensure the airspace was safe for takeoff. Under U.K. law, it is illegal to fly drones within 1 kilometer (0.62 mile) of an airport, and violators can face up to five years in prison.\n",
      "\n",
      "But this morning the airport announced that its only runway was available for arrivals and departures again. While officials there warned of \"knock-on delays and cancellations to flight,\" at least the gears had begun to turn again, however briefly.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
