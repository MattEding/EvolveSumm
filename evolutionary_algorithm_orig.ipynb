{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import operator\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "data = cwd / 'data'\n",
    "jsons = data / 'jsons'\n",
    "json_2018 = jsons / '2018'\n",
    "\n",
    "json_2018 = list(json_2018.iterdir())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people who don't get insurance through their jobs will now be able to buy short-term policies that may be cheaper than affordable care act coverage. these plans won't have to cover as many medical services and are exempt from covering people with pre-existing conditions.\n",
      "\n",
      "the departments of health and human services, labor and treasury announced new rules wednesday that make it easier for consumers to replace aca insurance with these short-term policies.\n",
      "\n",
      "the policies were originally limited to three months, but they can now last up to a year, and be renewed to last as long as three years. the plans have been a priority of president trump, who says he wants consumers to have access to cheaper health insurance.\n",
      "\n",
      "short-term plans don't have to meet the affordable care act's consumer protection and coverage requirements, so many will not cover services such as mental health care or prescription drugs. and insurance companies can deny customers coverage on these plans if they have a pre-existing medical condition and charge people more if they are likely to need medical care.\n",
      "\n",
      "\"these policies are different from those offered on the exchange,\" said james parker, a senior adviser for health reform at hhs, in a conference call with reporters. \"we make no representation that it's equivalent coverage.\"\n",
      "\n",
      "parker said a short-term policy may cost as little as $124 a month, compared with an average $393 for an unsubsidized policy that meets all the aca coverage requirements.\n",
      "\n",
      "\"if you start out healthy so that you get covered, but then later get a diagnosis, they can drop you at the end of the contract term,\" says sabrina corlette, a research professor at georgetown university's center on health insurance reforms.\n",
      "\n",
      "the affordable care act requires insurance companies to offer 10 essential health benefits including such things as maternity coverage and mental health care. it also requires insurance companies to cover anyone who wants to buy a policy and charge the same premium to everyone in a community.\n",
      "\n",
      "the goal was to ensure that everyone has access to quality health coverage without discriminating against those who have pre-existing medical conditions.\n",
      "\n",
      "but many people complained that the policies were too expensive.\n",
      "\n",
      "hhs estimates that about 200,000 people will buy short-term policies next year and as many as 1.6 million could own them after five years.\n",
      "\n",
      "the congressional budget office, the nonpartisan research office that estimates the budget effects of policy proposals, gave a larger figure, estimating that about 2 million mostly healthy people will buy short-term plans. this could have the effect of driving premiums slightly higher on the aca exchanges, because healthier people will leave the market, according to the cbo.\n",
      "\n",
      "the plans are aimed at people who earn more than four times the federal poverty threshold and therefore don't qualify for federal subsidies to help pay premiums for policies sold on the aca exchanges.\n",
      "\n",
      "many of those people have been priced out of the health insurance market since the aca took effect, says joseph antos, an economist at the american enterprise institute.\n",
      "\n",
      "\"this will at least provide a little bit of relief for people who are otherwise essentially forgotten by the affordable care act,\" antos says.\n",
      "\n",
      "short-term policies are available now, but consumers can only buy them for up to three months. according to a report by the national association of insurance commissioners, the policies paid out an average 55 percent of their premiums in actual health care last year. under the affordable care act, insurance companies are required to spend 80 to 85 percent of their premiums on health care or refund money to their customers.\n",
      "\n",
      "antos and corlette both say they don't expect the availability of short-term policies to have a major impact on the aca exchanges. that's because more than 85 percent of the people who get insurance through the exchanges qualify for subsidies that keep their premiums affordable and stable.\n",
      "\n",
      "the new rules will require extensive disclosure to ensure consumers know the limits of short-term policies, hhs officials said.\n",
      "\n",
      "more than 9,000 people and organizations commented on the rule, since february when it was first proposed. many comments came from people who said they have existing medical conditions that – before the affordable care act's consumer protections were put in place – would have been unable to get insurance that would cover their condition.\n",
      "\n",
      "a commenter from iowa, who has cystic fibrosis, wrote: \"people with cystic fibrosis require a complex and demanding care regimen, and need access to high-quality, specialized care and adequate and affordable insurance. the proposed rule fails to adequately protect our community.\"\n",
      "\n",
      "the new rules will require insurers to include clear explanations about what is covered, and to warn consumers that they do not have an automatic right to renew their policies when they expire. and if a short-term policy ends before the open enrollment period for affordable care act insurance, consumers will not have the right to buy aca insurance right away, says randy pate, the deputy administrator of the centers for medicare and medicaid services at hhs.\n",
      "\n",
      "\"the notice language urges people to read their policy very carefully to see what's included and what's not included,\" he says.\n",
      "\n",
      "corlette worries that won't be enough and people will be left surprised that their insurance doesn't cover them when they need care.\n",
      "\n",
      "\"it's very much buyer beware. and of course if you have any kind of pre-existing condition, or you want to have a baby or you're expecting to have serious medical needs taken care of these are not the plans for you,\" she says.\n",
      "\n",
      "the new rules go into effect in 60 days, so expanded short-term policies could be available in october.\n"
     ]
    }
   ],
   "source": [
    "with open(json_2018) as fp:\n",
    "    articles_2018 = json.load(fp)['2018']\n",
    "\n",
    "article = articles_2018[4]\n",
    "text = article['story'].lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Algorithms\n",
    "- [Discrete Differential Evolution for Text Summarization](https://www.researchgate.net/publication/281662415_Discrete_Differential_Evolution_for_Text_Summarization)\n",
    "- [Evolutionary Algorithm for Extractive Text Summarization](https://www.researchgate.net/profile/Ramiz_Aliguliyev/publication/220518077_Evolutionary_Algorithm_for_Extractive_Text_Summarization/links/09e4151356fc2caab6000000.pdf)\n",
    "- [An Improved Evolutionary Algorithm for Extractive Text Summarization](https://link.springer.com/chapter/10.1007/978-3-642-36543-0_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(text):\n",
    "    no_punctuation = ''.join(t for t in text if t not in string.punctuation)\n",
    "    return frozenset(tokenize.word_tokenize(no_punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let document $ D $ be decomposed into a set of $ n $ sentences.  \n",
    "$\n",
    "D = \\{ S_1, S_2, ..., S_n \\}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = document_sentences = set(tokenize.sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let terms $ T $ be the set of all $ m $ distinct words in $ D $.  \n",
    "$\n",
    "T = \\{ t_1, t_2, ..., t_m \\}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = document_distinct_words = distinct_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ S_i $ represent the set of distinct terms in sentence $ S_i $ with \n",
    "$ m_i $ distinct terms.  \n",
    "$\n",
    "S_i = \\{ t_1, t_2, ..., t_{ m_i } \\}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sentence_distinct_words = {distinct_words(ds) for ds in document_sentences}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Coefficient Similarity Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "sim_{ jaccard } ( S_i, S_j ) = \n",
    "\\dfrac\n",
    "    { | S_i \\cap S_j | }\n",
    "    { | S_i \\cup S_j | }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"however doctors learned that long inactivity did more harm than good\".split()\n",
    "b = \"patients got out of shape developed blood clots and became demoralized\".split()\n",
    "\n",
    "jaccard_similarity(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Google Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "\\text{NGD} ( t_k, t_l ) = \\dfrac \n",
    "    { \\text{max} \\big\\{\n",
    "        \\text{log} ( f_k ), \n",
    "        \\text{log} ( f_l )\n",
    "    \\big\\}\n",
    "    - \\text{log} ( f_{ lk } ) }\n",
    "    { \\text{log} ( n ) \n",
    "    - \\text{min} \\big\\{\n",
    "        \\text{log} ( f_k ), \n",
    "        \\text{log} ( f_l )\n",
    "    \\big\\} }\n",
    "$\n",
    "\n",
    "where:\n",
    "- $ t_k $ and $ t_l $ are terms \n",
    "- $ f_k $ is the number of sentences containing $ t_k $\n",
    "- $ f_{ kl } $ is the number of sentences containing both $ t_k $ and $ t_l $\n",
    "- $ n $ is the total number of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large \n",
    "sim_{ \\text{NGD} } ( t_k, t_l ) = \\text{exp} \n",
    "    \\big( - \\text{NGD} ( t_k, t_l ) \\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large \n",
    "sim_{ \\text{NGD} } ( S_i, S_j ) = \n",
    "\\dfrac\n",
    "    { \\sum\\limits\n",
    "        _{ \\small t_k \\in S_i } \n",
    "        \\sum\\limits\n",
    "            _{ \\small t_l \\in S_j } \n",
    "            sim_{ \\text{NGD} } ( t_k, t_l ) }\n",
    "    { m_i m_j }\n",
    "$  \n",
    "\n",
    "where:\n",
    "- $ S_i $ and $ S_j $ are sentences\n",
    "- $ m_i $ is the number of words in $ S_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedGoogle:\n",
    "    def __init__(self, document):\n",
    "        self.sentence_words = tuple(distinct_words(sent) for sent in tokenize.sent_tokenize(document))\n",
    "        \n",
    "    # double check scientific paper's handling of \"bad\" log values\n",
    "    def distance(self, term_k, term_l):\n",
    "        freq_k = sum(term_k in sent for sent in self.sentence_words)\n",
    "        freq_l = sum(term_l in sent for sent in self.sentence_words)\n",
    "        if not (freq_k and freq_l):\n",
    "            raise ValueError('terms must be in document')\n",
    "\n",
    "        freq_kl = sum((term_k in sent) and (term_l in sent) for sent in self.sentence_words)\n",
    "        if (freq_k > 0) and (freq_l > 0) and (freq_kl == 0):\n",
    "            return 1.0\n",
    "\n",
    "        logs_k_l = (math.log(freq_k), math.log(freq_l))\n",
    "        n = len(self.sentence_words)\n",
    "\n",
    "        numerator = max(logs_k_l) - math.log(freq_kl)\n",
    "        denominator = math.log(n) - min(logs_k_l)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def term_similarity(self, term_k, term_l):\n",
    "        dist = self.distance(term_k, term_l)\n",
    "        return math.exp(-dist)\n",
    "    \n",
    "    def sentence_similarity(self, sent_i, sent_j):\n",
    "        total = sum(self.term_similarity(term_k, term_l)\n",
    "                    for term_k, term_l in itertools.product(sent_i, sent_j))\n",
    "        return total / len(sent_i) / len(sent_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ C $ be a partition of $ D $ with $ k $ clusters.  \n",
    "$ C = \\{ C_1, C_2, ..., C_k \\} $  \n",
    "\n",
    "where:\n",
    "- $ C_p \\cap C_q = \\emptyset, \n",
    "        \\forall p \\ne q \\in \\{ 1, 2, ..., k \\} \n",
    "  $\n",
    "- $ \\bigcup\\limits\n",
    "    _{ p = 1 }\n",
    "    ^k C_p = D \n",
    "  $\n",
    "- $ C_p \\ne \\emptyset, \n",
    "        \\forall p \\in \\{ 1, 2, ..., k \\}\n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_clusters(clusters, document):\n",
    "    disjoint = all(not cluster_i & cluster_j for cluster_i, cluster_j in itertools.combinations(clusters, r=2))\n",
    "    union = functools.reduce(operator.or_, clusters) == document\n",
    "    nonempty = all(cluster for cluster in clusters)\n",
    "    if not (disjoint and union and nonempty):\n",
    "        raise ValueError('clusters do not form a partition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize(chromosome):\n",
    "    partition = collections.defaultdict(list)\n",
    "    for i, cluster in enumerate(chromosome):\n",
    "        partition[cluster].append(i)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "$\n",
    "\\large\n",
    "sigm ( x ) = \n",
    "\\dfrac\n",
    "    { 1 }\n",
    "    { 1 + \\text{exp} ( -x ) }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit as sigmoid\n",
    "# interesting this is 3x faster than my implimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-Cluster Similiarity (Cohesion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F_1 = \n",
    "\\sum\\limits\n",
    "    _{ \\small p = 1 }\n",
    "    ^{ \\small k } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_i, S_j \\in C_p } \n",
    "\\dfrac \n",
    "    { sim ( S_i, S_j ) } \n",
    "    { | C_p | } \n",
    "\\rightarrow \\text{max}\n",
    "$\n",
    "\n",
    "*(__Note:__ Evol Alg for Ext Txt Summ doesn't show division of $|C_p|$ but I believe this to be a typo since the paragraph detailing it says \"the average sum\". Additionally the Disc Diff Evol for Txt Summ shows it as such.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohesion(chromosome, sentences, sim):\n",
    "    total = 0\n",
    "    clusters = clusterize(chromosome)\n",
    "    for cluster in clusters.values():\n",
    "        for i, j in itertools.combinations(cluster, r=2):\n",
    "            sent_i, sent_j = sentences[[i,j]]\n",
    "            total += sim(sent_i, sent_j) / len(cluster)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Cluster Dissimilarity (Separation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F_2 = \n",
    "\\sum\\limits\n",
    "    _{ \\small p = 1 }\n",
    "    ^{ \\small k - 1 }\n",
    "\\sum\\limits\n",
    "    _{ \\small q = p + 1 }\n",
    "    ^{ \\small k } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_i \\in C_p } \n",
    "\\sum\\limits\n",
    "    _{ \\small S_j \\in C_q } \n",
    "\\dfrac \n",
    "    { sim ( S_i, S_j ) } \n",
    "    { | C_p | \\cdot | C_q | }\n",
    "\\rightarrow \\text{min}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation(chromosome, sentences, sim):\n",
    "    total = 0\n",
    "    clusters = clusterize(chromosome)\n",
    "    for cluster_p, cluster_q in itertools.combinations(clusters.values(), r=2):\n",
    "        for i, j in itertools.product(cluster_p, cluster_q):\n",
    "            sent_i, sent_j = sentences[[i,j]]\n",
    "            total += sim(sent_i, sent_j) / len(cluster_p) / len(cluster_q)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter/Intra-Cluster Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "F = \\big( 1 + sigm ( F_1 ) \\big)\n",
    "    ^{ F_2 } \\rightarrow \\text{max}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohesion_separation(chromosome, sentences, sim):\n",
    "    coh = cohesion(chromosome, sentences, sim)\n",
    "    sep = separation(chromosome, sentences, sim)\n",
    "    return pow(1 + sigmoid(coh), sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "fitness_1 \\big( X_a ( t ) \\big) = F_1 \\big( X_a ( t ) \\big)\n",
    "$\n",
    "\n",
    "$\n",
    "\\large\n",
    "fitness_2 \\big( X_a ( t ) \\big) = \\dfrac{ 1 }{ F_2 ( X_a ( t ) ) }\n",
    "$\n",
    "\n",
    "$\n",
    "\\large\n",
    "fitness \\big( X_a ( t ) \\big) = F \\big( X_a ( t ) \\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_1(chromosome, sentences, sim):\n",
    "    return cohesion(chromosome, sentences, sim)\n",
    "\n",
    "def fitness_2(chromosome, sentences, sim):\n",
    "    return 1 / separation(chromosome, sentences, sim)\n",
    "\n",
    "def fitness(chromosome, sentences, sim):\n",
    "    return cohesion_separation(chromosome, sentences, sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Discrete Differential Evolution Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the population with $ N $ chromosomes each composed of $ n $ random integers from \\[1, k\\].  \n",
    "\n",
    "$\n",
    "X_r ( t ) = [ x_{ r, 1 } ( t ), x_{ r, 2 } ( t ), ..., x_{ r, n } ( t ) ]\n",
    "$  \n",
    "\n",
    "where:\n",
    "- $ x_{ r, s } ( t ) \\in \\{ 1, 2, ..., k \\} $\n",
    "- $ r = 1, 2, ..., N $\n",
    "- $ s = 1, 2, ..., n $\n",
    "- $ N $ is the population size\n",
    "- $ n $ is the number of sentences _(in the document)_\n",
    "- $ k $ is the number of clusters _(number of sentences for summary)_\n",
    "- $ t $ is the iteration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: create more robust algorithm; however this is only run once for initialization\n",
    "def assign_clusters(num_of_clusters, num_of_sentences):\n",
    "    chromosome = []\n",
    "    while not all(num in chromosome for num in range(num_of_clusters)):\n",
    "        chromosome = np.random.choice(range(num_of_clusters), num_of_sentences)\n",
    "    return chromosome\n",
    "    \n",
    "\n",
    "def initialize_population(population_size, num_of_clusters, num_of_sentences):\n",
    "    if num_of_clusters > num_of_sentences:\n",
    "        raise ValueError('num_of_clusters cannot be greater than num_of_sentences')\n",
    "    population = np.array([assign_clusters(num_of_clusters, num_of_sentences) for _ in range(population_size)])\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "y_{ r, s } ( t + 1 ) = \n",
    "\\begin{cases}\n",
    "    x_{ r1, s } ( t ) + \\lambda \\big( x_{ r2, s } ( t ) - x_{ r3, s } ( t ) \\big) \n",
    "        & \\text{if } rand_s < \\text{CR} \\\\\n",
    "    x_{ r, s } ( t ) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where  \n",
    "- For each $ X_r $, randomly sample $ X_{ r1 } ( t ), X_{ r2 } ( t ), X_{ r3 } ( t ) $ \n",
    "  from the same generation _(each distinct)_\n",
    "- $ rand_s $ is uniformally distributed random numbers from $ [ 0, 1 ] $ \n",
    "  chosen once for each $ s \\in \\{ 1, 2, ..., n \\} $\n",
    "\n",
    "hyper-parameters \n",
    "- $ \\lambda $ is a scale factor from $ [ 0, 1 ] $\n",
    "- $ \\text{CR} $ is the crossover rate from $ [ 0, 1 ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_offspring(population, scaling_factor, crossover_rate, randoms):\n",
    "    population_size, num_of_sentences = population.shape\n",
    "    population_idxs = frozenset(range(population_size))\n",
    "    num_of_clusters = np.max(population)\n",
    "    offspring = population.copy()\n",
    "    \n",
    "    for i, (chrom, random) in enumerate(zip(population, randoms)):\n",
    "        #: must select chrom != chrom_l != chrom_m != chrom_n from population\n",
    "        choices = tuple(population_idxs - {i})\n",
    "        idxs = np.random.choice(choices, size=3, replace=False)\n",
    "        chrom_l, chrom_m, chrom_n = population[idxs]\n",
    "        \n",
    "        chromosomes = zip(chrom, chrom_l, chrom_m, chrom_n, random)\n",
    "        for j, (gene, gene_l, gene_m, gene_n, rand) in enumerate(chromosomes):\n",
    "            if rand < crossover_rate:\n",
    "                new_gene = (gene_l + scaling_factor * (gene_m - gene_n)) % num_of_clusters\n",
    "                offspring[i,j] = new_gene\n",
    "\n",
    "    return offspring\n",
    "\n",
    "\n",
    "def randomize(population):\n",
    "    return np.random.random_sample(population.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "X_r(t+1) = \n",
    "\\begin{cases}\n",
    "    Y_r ( t + 1 ) & \\text{if } f \\big( Y_r ( t + 1 ) \\big) > f \\big( X_r ( t ) \\big) \\\\\n",
    "    X_r ( t ) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where \n",
    "- $ f ( \\cdot ) $ is the objective function to be maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_generation(population, offspring, fitness):\n",
    "    next_gen = population.copy()\n",
    "    for i, (chrom_pop, chrom_off) in enumerate(zip(population, offspring)):\n",
    "        if fitness(chrom_off) > fitness(chrom_pop):\n",
    "            next_gen[i] = chrom_off\n",
    "    return next_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each iteration $ t + 1 $ for each $ X_r ( t ) $ creates\n",
    "$ m_r ( t + 1 ) = [ m_{ r, 1 } ( t ), m_{ r, 2 } ( t ), ..., m_{ r, n } ( t ) ] $.  \n",
    "For each gene, 1 indicates no mutation and 0 means mutate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "m_{ r, s } ( t + 1 ) = \n",
    "\\begin{cases}\n",
    "    1 & \\text{if } rand_s < sigm \\big( y_{ r, s } ( t + 1 ) \\big) \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(offspring, randoms):\n",
    "    mutations = np.empty_like(offspring)    \n",
    "    for i, (gene, rand) in enumerate(zip(offspring.ravel(), randoms.ravel())):\n",
    "        mutations.ravel()[i] = rand < sigmoid(gene)\n",
    "    return mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 - Psuedo-code\n",
    "<img src=\"./data/pngs/fig1_-_inversion_operator_psuedo_code.png\" alt=\"Fig 1. Inverse operator psuedo-code\" width=\"33%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversion_operator(chromosome, mutation):\n",
    "    next_gen = chromosome.copy()\n",
    "    idxs = set(i for i, mutate in enumerate(mutation) if not mutate)\n",
    "    \n",
    "    while len(idxs):\n",
    "        i_min, i_max = min(idxs), max(idxs)\n",
    "        next_gen[i_min] = chromosome[i_max]\n",
    "        next_gen[i_max] = chromosome[i_min]\n",
    "        idxs -= {i_max, i_min}\n",
    "    \n",
    "    return next_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_partition(clusters, document):\n",
    "    disjoint = all(not cluster_i & cluster_j for cluster_i, cluster_j in itertools.combinations(clusters, r=2))\n",
    "    union = functools.reduce(operator.or_, clusters) == document\n",
    "    nonempty = all(cluster for cluster in clusters)\n",
    "    if not (disjoint and union and nonempty):\n",
    "        raise ValueError('clusters do not form a partition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2 - Example\n",
    "<img src=\"./data/pngs/fig2_-_inversion_operator_diagram.png\" alt=\"Fig 2. Inverse operator example\" width=\"33%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing Fig 2. input/output\n",
    "chromosome = [3, 2, 4, 2, 3, 1, 4, 1]\n",
    "mutation = [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "next_gen = [4, 2, 4, 1, 3, 2, 3, 1]\n",
    "\n",
    "assert inversion_operator(chromosome, mutation) == next_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c6a8ade8d501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mevolved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve_generations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossover_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-c6a8ade8d501>\u001b[0m in \u001b[0;36mevolve_generations\u001b[0;34m(population, criterion, scaling_factor, crossover_rate, iterations)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrandoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_offspring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossover_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgeneration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-c550d5026958>\u001b[0m in \u001b[0;36mnext_generation\u001b[0;34m(population, offspring, fitness)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnext_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchrom_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchrom_off\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrom_off\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrom_pop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mnext_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchrom_off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-7f55d9424381>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(chromosome, sentences, sim)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcohesion_separation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2cd43b605b2a>\u001b[0m in \u001b[0;36mcohesion_separation\u001b[0;34m(chromosome, sentences, sim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcohesion_separation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcoh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcohesion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-49527a6231f9>\u001b[0m in \u001b[0;36mseparation\u001b[0;34m(chromosome, sentences, sim)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0msent_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_p\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4163644fb80d>\u001b[0m in \u001b[0;36mjaccard_similarity\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evolve_generations(population, criterion, scaling_factor, crossover_rate, iterations):\n",
    "    for idx in range(iterations):\n",
    "        print(idx)\n",
    "        randoms = randomize(population)\n",
    "        offspring = generate_offspring(population, scaling_factor, crossover_rate, randoms)\n",
    "        generation = next_generation(population, offspring, criterion)\n",
    "        mutations = mutate(generation, randoms)\n",
    "        for i, (chromosome, mutation) in enumerate(zip(generation, mutations)):\n",
    "            generation[i] = inversion_operator(chromosome, mutation)\n",
    "        population = generation\n",
    "    return population\n",
    "\n",
    "\n",
    "scaling_factor = 0.9\n",
    "crossover_rate = 0.5\n",
    "criterion = functools.partial(fitness, sentences=np.array(list(document_sentences)), sim=jaccard_similarity)\n",
    "population = initialize_population(population_size=100, num_of_clusters=5, num_of_sentences=len(document_sentences))\n",
    "evolved = evolve_generations(population, criterion, scaling_factor, crossover_rate, iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE-N\n",
    "_(Recall Oriented Understudy for Gisting Evaluation)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large\n",
    "\\text{ROUGE-N} = \n",
    "\\dfrac\n",
    "    { \\sum \\limits\n",
    "        _{ \\small S \\in Summ_{ ref }} \n",
    "        \\sum \\limits\n",
    "        _{ \\small \\text{N-gram} \\in S } \n",
    "            Count_{ \\small match } ( \\text{N-gram} ) }\n",
    "    { \\sum \\limits\n",
    "        _{ \\small S \\in Summ_{ ref } } \n",
    "        \\sum \\limits\n",
    "            _{ \\small \\text{N-gram} \\in S } \n",
    "            Count( \\text{N-gram} ) }\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(n, y_pred, y_true):\n",
    "    n_gram_pred = set(ngrams(y_pred, n))\n",
    "    n_gram_true = set(ngrams(y_true, n))\n",
    "    return len(n_gram_pred & n_gram_true) / len(n_gram_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/#how_to_evaluate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = 'a good diet must have apples and bananas'.split()\n",
    "y_pred = 'apples and bananas are must for a good diet'.split()\n",
    "\n",
    "assert rouge_n(1, y_pred, y_true) == 7 / 8\n",
    "assert rouge_n(2, y_pred, y_true) == 4 / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
