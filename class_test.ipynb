{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import itertools\n",
    "import logging\n",
    "import multiprocessing\n",
    "import pathlib\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "@njit\n",
    "def jaccard(a, b):\n",
    "    union = np.sum(a | b)\n",
    "    if not union:\n",
    "        return 1.0\n",
    "    return np.sum(a & b) / union\n",
    "\n",
    "\n",
    "@njit\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class DdeSummarizer:\n",
    "    \"\"\"Discrete differential evolution (DDE) extractive text summarizer.\n",
    "        \n",
    "    This implementation is derived from:\n",
    "    [1] R. Alguliev, R. Aliguliyev \"Evolutionary Algorithm for Extractive Text Summarization\" 2009\n",
    "    [2] S. Das, P.N. Suganthan \"Differential Evolution: A Survey of the State-of-the-Art\" 2011\n",
    "    [3] A. Abuobieda, N. Salim, Y.J. Kumar, A.H. Osman \"An Improved Evolutionary Algorithm for Extractive Text Summarization\" 2013\n",
    "    [4] S. Karwa, N. Chatterjee \"Discrete Differential Evolution for Text Summarization\" 2014\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pop_size : int, (default=100)\n",
    "        The population size to create offspring and mutate over.\n",
    "\n",
    "    max_iter : int, (default=1000)\n",
    "        The maximum number of generations to evolve.\n",
    "\n",
    "    summ_ratio : float, (default=0.1)\n",
    "        The compression ratio for the summary, with 0 <= summ_ratio <= 1.\n",
    "\n",
    "    lam : float, (default=0.5)\n",
    "        The scale factor used with DDE, with 0 <= lam <= 1.\n",
    "\n",
    "    crossover : float, (default=0.5)\n",
    "        The crossover rate used for offspring, with 0 <= summ_ratio <= 1.\n",
    "\n",
    "    fitness : str, 'coh_sep', 'coh', or 'sep', (default='coh_sep')\n",
    "        The fitness function used to determine which chromosomes make it to the\n",
    "        next generation. The 'coh' fitness maximizes similarity within a given\n",
    "        cluster. The 'sep' fitness minimizes similarity between different\n",
    "        clusters. The 'coh_sep' is a balance of the former two.\n",
    "\n",
    "    similarity : callable, (default=jaccard)\n",
    "        Similarity function for comparing two arrays. Needs to be able to work\n",
    "        with numba.\n",
    "\n",
    "    metric : str, or callable, (default='cosine')\n",
    "        Metric used to select central sentences from clusters when finished with\n",
    "        iterating through generations.\n",
    "        See sklearn.metrics.pairwise_distances for details.\n",
    "\n",
    "    tokenizer : callable, (default=nltk.tokenize.sent_tokenize)\n",
    "        Tokenizer used to split text when fit.\n",
    "\n",
    "    stop_words : str, list, or None (default=None):\n",
    "        Words to remove from document.\n",
    "        See sklearn.feature_extraction.text.CountVectorizer for details.\n",
    "\n",
    "    n_jobs : int, (default=1)\n",
    "        The number of CPUs to score fitness of each chromosome in the population\n",
    "        at each generation. -1 means usings all processors.\n",
    "\n",
    "    early_stopping : bool, (default=False)\n",
    "        Whether to use early stopping to terminate iterations when fitness score\n",
    "        is not improving.\n",
    "\n",
    "    n_iter_no_change : int, (default=5)\n",
    "        Number of iterations with no improvement to wait before early stopping.\n",
    "\n",
    "    tol : float, (default=1e-3)\n",
    "        The stopping criterion.\n",
    "\n",
    "    random_state : int, (default=None)\n",
    "        The seed of the pseudo random number generator to use when evolving To\n",
    "        be passed to np.random.seed.\n",
    "\n",
    "    verbose : int, (default=0)\n",
    "        The verbosity level.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pop_size=100, max_iter=1000, summ_ratio=0.1, lam=0.5, crossover=0.5,\n",
    "                 fitness='coh_sep', similarity=jaccard, metric='cosine', tokenizer=sent_tokenize,\n",
    "                 stop_words=None, n_jobs=1, early_stopping=False, n_iter_no_change=5,\n",
    "                 tol=1e-3, random_state=None, verbose=0):\n",
    "\n",
    "        self.pop_size = int(pop_size)\n",
    "        self.max_iter = int(max_iter)\n",
    "        self.n_jobs = int(n_jobs)\n",
    "        self.early_stopping = bool(early_stopping)\n",
    "        self.n_iter_no_change = int(n_iter_no_change) if (n_iter_no_change > 1) else 1\n",
    "        self.tol = float(tol)\n",
    "        self.random_state = random_state\n",
    "        self.verbose = max(0, int(verbose))\n",
    "        self.stop_words = stop_words\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metric = str(metric).lower()\n",
    "\n",
    "        self._pop = None\n",
    "        self._offspr = None\n",
    "        self._rand = None\n",
    "\n",
    "        funcs = dict(coh_sep=self._cohesion_separation, coh=self._cohesion, sep=self._separation)\n",
    "        self.fitness = funcs[fitness.lower()]\n",
    "\n",
    "        if (summ_ratio < 0) or (summ_ratio > 1):\n",
    "            raise ValueError('summ_ratio not in interval [0, 1]')\n",
    "        self.summ_ratio = float(summ_ratio)\n",
    "\n",
    "        if (lam < 0) or (lam > 1):\n",
    "            raise ValueError('lam not in interval [0, 1]')\n",
    "        self.lam = float(lam)\n",
    "\n",
    "        if (crossover < 0) or (crossover > 1):\n",
    "            raise ValueError('crossover not in interval [0, 1]')\n",
    "        self.crossover = float(crossover)\n",
    "\n",
    "        #TODO: use inspect.signature to see if it takes 2 inputs?\n",
    "        if not callable(similarity):\n",
    "            raise ValueError('similarity must be callable')\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def __repr__(self):\n",
    "        fitness = '_'.join(fit[:3] for fit in self.fitness.__name__.split('_') if fit)\n",
    "        return (f'{type(self).__name__}(pop_size={self.pop_size}, max_iter={self.max_iter}, '\n",
    "                f'summ_ratio={self.summ_ratio}, lam={self.lam}, crossover={self.crossover}, '\n",
    "                f'fitness={fitness!r}, similarity={self.similarity.__name__}, metric={self.metric!r}, '\n",
    "                f'tokenizer={self.tokenizer.__name__}, stop_words={self.stop_words!r}, n_jobs={self.n_jobs}, '\n",
    "                f'early_stopping={self.early_stopping}, n_iter_no_change={self.n_iter_no_change}, '\n",
    "                f'tol={self.tol}, random_state={self.random_state}, verbose={self.verbose})')\n",
    "\n",
    "    def fit(self, text):\n",
    "        \"\"\"Fit text to model.\"\"\"\n",
    "        self.text = str(text)\n",
    "        self._tokens = self.tokenizer(self.text.lower())\n",
    "        count_vec = CountVectorizer(stop_words=self.stop_words).fit_transform(self._tokens)\n",
    "        #: numba does not support sparse matrices\n",
    "        self._document = count_vec.toarray().astype(bool)\n",
    "        self._summ_len = int(self.summ_ratio * self._document.shape[1]) or 1        \n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"Create extractive summary using DDE.\"\"\"\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.debug(repr(self))\n",
    "            logging.info(self.text)\n",
    "            logging.debug('random seed: {}'.format(self.random_state))\n",
    "            if self.verbose >= 2:\n",
    "                logging.info('random state: {}'.format(np.random.get_state()))\n",
    "\n",
    "        processes = self.n_jobs if (self.n_jobs >= 1) else None\n",
    "        pool = multiprocessing.Pool(processes)\n",
    "        n_iter_deque = collections.deque([np.nan] * self.n_iter_no_change, maxlen=self.n_iter_no_change)\n",
    "        self._pop = np.array([self._init_chrom() for _ in range(self.pop_size)])\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            self._rand = np.random.random_sample(self._pop.shape)\n",
    "            self._offspring()\n",
    "            self._survival(pool)\n",
    "            self._mutate()\n",
    "            \n",
    "            if self.verbose:\n",
    "                logging.debug('iteration: {}'.format(i))\n",
    "                if self.verbose >= 2:\n",
    "                    logging.debug('best fit: {}'.format(self._best_fit))\n",
    "\n",
    "            if self.early_stopping:\n",
    "                n_iter_deque.append(self._best_fit)\n",
    "                if max(n_iter_deque) - min(n_iter_deque) < self.tol:\n",
    "                    break\n",
    "\n",
    "        pool.terminate()\n",
    "        self.n_iter_ = i + 1\n",
    "        idx = np.argmax([self.fitness(chrom) for chrom in self._pop])\n",
    "        self.best_chrom_ = self._pop[idx]\n",
    "        self._build_summ()\n",
    "\n",
    "    def _init_chrom(self):\n",
    "        clusters = np.arange(self._summ_len)\n",
    "        chrom = np.full(len(self._document), -1)\n",
    "        #: ensure that each cluster is accounted for at least once\n",
    "        idxs = np.random.choice(np.arange(len(chrom)), self._summ_len, replace=False)\n",
    "        chrom[idxs] = np.random.permutation(clusters)\n",
    "        #: fill rest randomly\n",
    "        idxs = (chrom == -1)\n",
    "        chrom[idxs] = np.random.choice(clusters, np.sum(idxs))\n",
    "        return chrom\n",
    "\n",
    "    def _offspring(self):\n",
    "        n = np.arange(len(self._pop))\n",
    "        s = frozenset(n)\n",
    "        #: get 3 distinct chromosomes that differ from i_th chromosome\n",
    "        idxs = np.array([np.random.choice(tuple(s - {i}), size=3, replace=False) for i in n])\n",
    "        chrom_1, chrom_2, chrom_3 = map(np.squeeze, np.split(self._pop[idxs], 3, axis=1))\n",
    "        #: discrete differential evolution\n",
    "        self._offspr = (chrom_1 + self.lam * (chrom_2 - chrom_3)) % self._summ_len\n",
    "        mask = self._rand < self.crossover\n",
    "        self._offspr[mask] = self._pop[mask]\n",
    "        return\n",
    "\n",
    "    def _survival(self, pool):\n",
    "        fits = pool.map(self.fitness, itertools.chain(self._pop, self._offspr))\n",
    "        self._best_fit = max(fits)  # used for early stopping\n",
    "        i = len(self._pop)\n",
    "        fit_pop, fit_off = fits[:i], fits[i:]\n",
    "        mask = fit_off > fit_pop\n",
    "        self._pop[mask] = self._offspr[mask]\n",
    "        return\n",
    "\n",
    "    def _mutate(self):\n",
    "        mask = self._rand < sigmoid(self._pop)\n",
    "        #: inversion operator -> for each row reverse order of all True values\n",
    "        idxs = np.nonzero(mask)\n",
    "        arr = np.array(idxs)\n",
    "        sorter = np.lexsort((-arr[1], arr[0]))\n",
    "        rev = arr.T[sorter].T\n",
    "        self._pop[idxs] = self._pop[(rev[0], rev[1])]\n",
    "        return\n",
    "\n",
    "    def _central_sents(self):\n",
    "        central_idxs = []\n",
    "        for cluster in np.unique(self.best_chrom_):\n",
    "            idxs = np.where(self.best_chrom_ == cluster)[0]\n",
    "            sents = self._document[idxs]\n",
    "            centroid = sents.mean(axis=0)[np.newaxis,:]\n",
    "            dists = pairwise_distances(sents, centroid, self.metric)\n",
    "            cent_sent = idxs[np.argmin(dists)]\n",
    "            central_idxs.append(cent_sent)\n",
    "        return sorted(central_idxs)\n",
    "\n",
    "    def _build_summ(self):\n",
    "        central = self._central_sents()\n",
    "        summ = []\n",
    "        for sent in np.array(self._tokens)[central]:\n",
    "            start = self.text.lower().index(sent)\n",
    "            stop = start + len(sent)\n",
    "            summ.append(self.text[start:stop])\n",
    "        self.summary_ = '\\n'.join(summ)\n",
    "        return\n",
    "    \n",
    "    def _cohesion(self, chrom):\n",
    "        return _cohesion(chrom, self._document, self.similarity)\n",
    "    \n",
    "    def _separation(self, chrom):\n",
    "        return 1 / _separation(chrom, self._document, self.similarity)\n",
    "    \n",
    "    def _cohesion_separation(self, chrom):\n",
    "        return _cohesion_separation(chrom, self._document, self.similarity)\n",
    "\n",
    "\n",
    "#: numba doesn't work in class\n",
    "@njit\n",
    "def _cohesion(chrom, doc, sim):\n",
    "    total = 0\n",
    "    for p in np.unique(chrom):\n",
    "        sents = doc[chrom == p]\n",
    "        k = len(sents)\n",
    "        #: itertools.combinations(sents, r=2)\n",
    "        for i in range(k-1):\n",
    "            for j in range(i+1, k):\n",
    "                total += sim(sents[i], sents[j]) / len(sents)\n",
    "    return total\n",
    "\n",
    "@njit\n",
    "def _separation(chrom, doc, sim):\n",
    "    total = 0\n",
    "    k = len(np.unique(chrom))\n",
    "    #: itertools.combinations(k, r=2)\n",
    "    for p in range(k-1):\n",
    "        for q in range(p+1, k):\n",
    "            sents_p = doc[chrom == p]\n",
    "            sents_q = doc[chrom == q]\n",
    "            #: itertools.product(sents_p, sents_q)\n",
    "            m, n = len(sents_p), len(sents_q)\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    total += sim(sents_p[i], sents_q[j]) / m / n\n",
    "    return total\n",
    "\n",
    "@njit\n",
    "def _cohesion_separation(chrom, doc, sim):\n",
    "    coh = _cohesion(chrom, doc, sim)\n",
    "    sep = _separation(chrom, doc, sim)\n",
    "    return (1 + sigmoid(coh)) ** sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True! --nervous --very, very dreadfully nervous I had been and am; but why will you say that I am ma'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "data = cwd / 'data'\n",
    "txts = data / 'txts'\n",
    "\n",
    "tell_tale_heart_txt = txts / 'tell_tale_heart.txt'\n",
    "with open(tell_tale_heart_txt) as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dde_summ = DdeSummarizer(pop_size=50, max_iter=500, summ_ratio=0.05, stop_words='english', \n",
    "                         n_jobs=-1, random_state=0, early_stopping=True)\n",
    "dde_summ.fit(text)\n",
    "dde_summ.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever it fell upon me, my blood ran cold; and so by degrees --very gradually --I made up my mind to take the life of the old man, and thus rid myself of the eye forever.\n",
      "I was never kinder to the old man than during the whole week before I killed him.\n",
      "And then, when I had made an opening sufficient for my head, I put in a dark lantern, all closed, closed, that no light shone out, and then I thrust in my head.\n",
      "It took me an hour to place my whole head within the opening so far that I could see him as he lay upon his bed.\n",
      "would a madman have been so wise as this, And then, when my head was well in the room, I undid the lantern cautiously-oh, so cautiously --cautiously (for the hinges creaked) --I undid it just so much that a single thin ray fell upon the vulture eye.\n",
      "And every morning, when the day broke, I went boldly into the chamber, and spoke courageously to him, calling him by name in a hearty tone, and inquiring how he has passed the night.\n",
      "His room was as black as pitch with the thick darkness, (for the shutters were close fastened, through fear of robbers,) and so I knew that he could not see the opening of the door, and I kept pushing it on steadily, steadily.\n",
      "I had my head in, and was about to open the lantern, when my thumb slipped upon the tin fastening, and the old man sprang up in bed, crying out --\"Who's there?\"\n",
      "I knew what the old man felt, and pitied him, although I chuckled at heart.\n",
      "And it was the mournful influence of the unperceived shadow that caused him to feel --although he neither saw nor heard --to feel the presence of my head within the room.\n",
      "When I had waited a long time, very patiently, without hearing him lie down, I resolved to open a little --a very, very little crevice in the lantern.\n",
      "So I opened it --you cannot imagine how stealthily, stealthily --until, at length a simple dim ray, like the thread of the spider, shot from out the crevice and fell full upon the vulture eye.\n",
      "I saw it with perfect distinctness --all a dull blue, with a hideous veil over it that chilled the very marrow in my bones; but I could see nothing else of the old man's face or person: for I had directed the ray as if by instinct, precisely upon the damned spot.\n",
      "It was the beating of the old man's heart.\n",
      "And now at the dead hour of the night, amid the dreadful silence of that old house, so strange a noise as this excited me to uncontrollable terror.\n",
      "With a loud yell, I threw open the lantern and leaped into the room.\n",
      "I then replaced the boards so cleverly, so cunningly, that no human eye --not even his --could have detected any thing wrong.\n",
      "A shriek had been heard by a neighbour during the night; suspicion of foul play had been aroused; information had been lodged at the police office, and they (the officers) had been deputed to search the premises.\n",
      "In the enthusiasm of my confidence, I brought chairs into the room, and desired them here to rest from their fatigues, while I myself, in the wild audacity of my perfect triumph, placed my own seat upon the very spot beneath which reposed the corpse of the victim.\n",
      "But, ere long, I felt myself getting pale and wished them gone.\n",
      "No doubt I now grew very pale; --but I talked more fluently, and with a heightened voice.\n",
      "I arose and argued about trifles, in a high key and with violent gesticulations; but the noise steadily increased.\n",
      "It grew louder --louder --louder!\n",
      "I could bear those hypocritical smiles no longer!\n"
     ]
    }
   ],
   "source": [
    "print(dde_summ.summary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dde_summ.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22,  6, 18, 12, 11,  4,  9, 11, 11,  9, 15,  1, 21, 22, 16,  1,  7,\n",
       "        6,  1,  3, 12, 18,  3,  0, 18, 16, 17, 23,  1,  5, 19, 14, 13, 14,\n",
       "        2,  3, 13, 16, 23,  2, 20,  2,  7, 11,  8, 23,  6, 13, 11, 13, 19,\n",
       "        9,  9,  9, 15, 14, 17,  0, 11, 20,  8,  6,  1,  4, 20,  9,  7,  3,\n",
       "       10, 18,  9,  4, 20,  1, 12,  6,  0, 18,  9, 17, 14,  1,  8, 16,  8,\n",
       "       10, 20,  6,  2, 12, 12,  4, 17,  5, 11,  1, 17,  4,  9,  9,  3, 19,\n",
       "       21,  7,  0, 12,  9,  6,  1, 20,  3,  1, 16,  4,  5,  6, 15, 21, 16,\n",
       "       23, 23, 21,  0, 10, 20, 20,  2, 22, 22, 11, 10,  7,  2, 10, 17, 13,\n",
       "       17, 22,  8, 10, 21, 13,  4,  0,  7, 19,  6,  9,  0, 16,  8, 23, 19,\n",
       "        8, 21, 11, 15, 19,  7,  4,  5,  0, 12,  6, 21,  4, 21, 21])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dde_summ.best_chrom_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
