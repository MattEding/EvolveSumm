{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import logging\n",
    "import multiprocessing\n",
    "import pathlib\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def jaccard_similarity(a, b):\n",
    "    union = np.sum(a | b)\n",
    "    if not union:\n",
    "        return 1.0\n",
    "    return np.sum(a & b) / union\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def cohesion(chromosome, similarity, document):\n",
    "    total = 0\n",
    "    for p in np.unique(chromosome):\n",
    "        sents = document[chromosome == p]\n",
    "        k = len(sents)\n",
    "        #: combinations choose 2\n",
    "        for i in range(k-1):\n",
    "            for j in range(i+1, k):\n",
    "                total += similarity(sents[i], sents[j]) / len(sents)  \n",
    "    return total\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def separation(chromosome, similarity, document):\n",
    "    total = 0\n",
    "    k = len(np.unique(chromosome))\n",
    "    #: combinations choose 2\n",
    "    for p in range(k-1):\n",
    "        for q in range(p+1, k):\n",
    "            sents_p = document[chromosome == p]\n",
    "            sents_q = document[chromosome == q]\n",
    "            #: product\n",
    "            m, n = len(sents_p), len(sents_q)\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    total += similarity(sents_p[i], sents_q[j]) / m / n\n",
    "    return total\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def cohesion_separation(chromosome, similarity, document):\n",
    "    coh = cohesion(chromosome, similarity, document)\n",
    "    sep = separation(chromosome, similarity, document)\n",
    "    return (1 + sigmoid(coh)) ** sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_chromosome(choices, length):\n",
    "    chrom = np.full(length, -1)\n",
    "    #: ensure that each choice is accounted for at least once\n",
    "    idxs = np.random.choice(np.arange(length), len(choices), replace=False)\n",
    "    chrom[idxs] = np.random.permutation(choices)\n",
    "    idxs = np.where(chrom == -1)[0]\n",
    "    chrom[idxs] = np.random.choice(choices, len(idxs))\n",
    "    return chrom\n",
    "\n",
    "\n",
    "def init_population(population_size, cluster_amount, chromosome_length):\n",
    "    clusts = np.arange(cluster_amount)\n",
    "    chroms = [init_chromosome(clusts, chromosome_length) for _ in range(population_size)]\n",
    "    pop = np.vstack(chroms)\n",
    "    return pop\n",
    "\n",
    "\n",
    "def get_offspring_distinct(population, randoms, lambda_, crossover_rate):\n",
    "    n = np.arange(len(population))\n",
    "    s = set(n)\n",
    "    idxs = np.array([np.random.choice(tuple(s - {i}), size=3, replace=False) for i in n])\n",
    "    chrom_1, chrom_2, chrom_3 = map(np.squeeze, np.split(population[idxs], 3, axis=1))\n",
    "    k = len(np.unique(population))\n",
    "    offspr = (chrom_1 + lambda_ * (chrom_2 - chrom_3)) % k\n",
    "    mask = randoms < crossover_rate\n",
    "    offspr[mask] = population[mask]\n",
    "    return offspr\n",
    "\n",
    "\n",
    "def get_offspring(population, randoms, lambda_, crossover_rate):\n",
    "    #: For computation time, relax requirement that X_r, X_r1, X_r2, X_r3 are distinct. \n",
    "    #: With large population size, this is unlikely to occur, and if it does, it doesn't\n",
    "    #: seem that detrimental. Also is this mitigated with appropriate lam choice?\n",
    "    n = len(population)\n",
    "    idxs = np.random.choice(np.arange(n), size=(n, 3))\n",
    "    chrom_1, chrom_2, chrom_3 = map(np.squeeze, np.split(population[idxs], 3, axis=1))\n",
    "    k = len(np.unique(population))\n",
    "    offspr = (chrom_1 + lambda_ * (chrom_2 - chrom_3)) % k\n",
    "    mask = randoms < crossover_rate\n",
    "    offspr[mask] = population[mask]\n",
    "    return offspr\n",
    "\n",
    "\n",
    "def next_generation(population, offspring, func, pool):\n",
    "    fits = pool.map(func, itertools.chain(population, offspring))\n",
    "    l = len(population)\n",
    "    fit_pop = np.array(fits[:l])\n",
    "    fit_off = np.array(fits[l:])\n",
    "    mask = fit_off > fit_pop\n",
    "    population[mask] = offspring[mask]\n",
    "    return\n",
    "\n",
    "\n",
    "def mutate(population, randoms):\n",
    "    mask = randoms < sigmoid(population)\n",
    "    #: inversion operator\n",
    "    idxs = np.nonzero(mask)\n",
    "    arr = np.array(idxs)\n",
    "    sorter = np.lexsort((-arr[1], arr[0]))\n",
    "    rev = arr.T[sorter].T\n",
    "    population[idxs] = population[(rev[0], rev[1])]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: early stopping --> little fitness improvement over x generations, good enough fitness score\n",
    "def run_iterations(pop_size, summ_len, num_sents, func, lam, cr, iterations, *, \n",
    "                   seed=None, verbose=False, save_rate=np.nan, save_dir=None):\n",
    "    \n",
    "    if verbose:\n",
    "        logging.info(f'pop_size={pop_size}, summ_len={summ_len}, func={func}, lam={lam}, cr={cr}, iterations={iterations}, seed={seed}')\n",
    "    \n",
    "    if save_dir is not None:\n",
    "        save_dir = pathlib.Path(save_dir)\n",
    "        if not save_dir.is_dir():\n",
    "            msg = f'save_dir={save_dir} not a valid directory path'.format(save_dir=save_dir)\n",
    "            raise NotADirectoryError(msg)\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    if isinstance(summ_len, int):\n",
    "        if not (0 < summ_len < num_sents):\n",
    "            raise ValueError('int summ_len must be between 0 and the number of sentences in the document')\n",
    "    elif isinstance(summ_len, float):\n",
    "        if not (0.0 < summ_len < 1.0):\n",
    "            raise ValueError('float summ_len must be between 0.0 and 1.0')\n",
    "        summ_len = int(summ_len * num_sents)\n",
    "    else:\n",
    "        raise TypeError('summ_len must be a float or int')\n",
    "        \n",
    "    pool = multiprocessing.Pool()\n",
    "    pop = init_population(pop_size, summ_len, num_sents)\n",
    "    shape = pop.shape\n",
    "    for i in range(iterations):\n",
    "        if i % save_rate == 0:\n",
    "            file = save_dir / 'generation_{i:0>pad}'.format(i=i, pad=len(str(iterations)))\n",
    "            np.save(file, pop)\n",
    "            \n",
    "        if verbose:\n",
    "            logging.info(f'iteration: {i}')\n",
    "            #TODO: logfile --> iteration number, best fitness score, avg fitness score, hyper-params\n",
    "        \n",
    "        rand = np.random.random_sample(shape)\n",
    "        offspr = get_offspring(pop, rand, lam, cr)\n",
    "        next_generation(pop, offspr, func, pool)\n",
    "        mutate(pop, rand)\n",
    "\n",
    "    pool.terminate()\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_chromosome(population):\n",
    "    #TODO: make sure it picks one with all k-clusters\n",
    "    fits = np.argmax([fitness(chrom) for chrom in population])\n",
    "    chrom = population[fits]\n",
    "    return chrom\n",
    "    \n",
    "\n",
    "def central_sentences(chromosome, document, metric=cosine_distances):\n",
    "    central_sents = []\n",
    "    for cluster in np.unique(chromosome):\n",
    "        idxs = np.where(chromosome == cluster)[0]\n",
    "        sents = document[idxs]\n",
    "        centroid = sents.mean(axis=0)[np.newaxis,:]\n",
    "        dists = metric(sents, centroid)\n",
    "        cent_sent = idxs[np.argmin(dists)]\n",
    "        central_sents.append(cent_sent)\n",
    "    return sorted(central_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(n, y_pred, y_true):\n",
    "    n_gram_pred = set(ngrams(y_pred, n))\n",
    "    n_gram_true = set(ngrams(y_true, n))\n",
    "    return len(n_gram_pred & n_gram_true) / len(n_gram_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every Who Down in Whoville Liked Christmas a lot...\\nBut the Grinch,Who lived just north of Whoville,'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "path = cwd / 'data' / 'grinch.txt'\n",
    "with open(path) as fp:\n",
    "    text = fp.read()\n",
    "    \n",
    "logfile = cwd / f'{path.stem}.log'\n",
    "logfile.touch()\n",
    "fmt = '{name} - {asctime} - {levelname} : {message}'\n",
    "logging.basicConfig(filename=logfile, level=logging.INFO, style='{', format=fmt)\n",
    "\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(chromosome):\n",
    "    return cohesion_separation(chromosome, jaccard_similarity, doc)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "sents_lower = tokenize.sent_tokenize(text.lower())\n",
    "sents_lower = (sent.split('\\n') for sent in sents_lower)\n",
    "sents_lower = tuple(itertools.chain.from_iterable(sents_lower))\n",
    "vec = cv.fit_transform(sents_lower)\n",
    "doc = vec.toarray().astype(bool).astype(int)\n",
    "ratio = 0.05\n",
    "\n",
    "logging.info('started iterations')\n",
    "pop = run_iterations(pop_size=100, summ_len=ratio, num_sents=len(doc), \n",
    "                     func=fitness, lam=0.5, cr=0.5, iterations=1000, verbose=True, seed=0)\n",
    "\n",
    "logging.info('finished iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_orig(idxs):\n",
    "    summ_evol = []\n",
    "    for sent in np.array(sents_lower)[idxs]:\n",
    "        start = text.lower().index(sent)\n",
    "        stop = start + len(sent)\n",
    "        summ_evol.append(text[start:stop])\n",
    "    summ_evol = '\\n'.join(summ_evol)\n",
    "    return summ_evol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The Grinch hated Christmas!\n",
      "1 Then the Whos, young and old, would sit down to a feast.\n",
      "2 And the more the Grinch thought of this Who ChristmasSing,\n",
      "3 \"I MUST stop this Christmas from coming!\n",
      "4 THE GRINCH GOT A WONDERFUL, AWFUL IDEA!\n",
      "5 Toward the homes where the Whos Lay asnooze in their town.\n",
      "6 When he heard a small sound like the coo of a dove.\n",
      "7 She stared at the Grinch and said, \"Santy Claus, why,”\n",
      "8 That the Grinch's small heart Grew three sizes that day!\n",
      "9 And the minute his heart didn't feel quite so tight,\n"
     ]
    }
   ],
   "source": [
    "chrom_best = best_chromosome(pop)\n",
    "np.save(f'{path.stem}', chrom_best)\n",
    "logging.info('saved npy')\n",
    "\n",
    "pair_dist = functools.partial(pairwise_distances, metric='cosine')\n",
    "idxs = central_sentences(chrom_best, doc, pair_dist)\n",
    "summ_evol = retrieve_orig(idxs)\n",
    "for i, sent in enumerate(summ_evol.split('\\n'), start=0):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’, ‘manhattan’,\n",
    "# ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’, ‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Every Who Down in Whoville Liked Christmas a lot...\n",
      "2 The Grinch hated Christmas!\n",
      "3 He stood there on Christmas Eve, hating the Whos,\n",
      "4 The more the Grinch thought, \"I must stop this whole thing!\"\n",
      "5 THE GRINCH GOT A WONDERFUL, AWFUL IDEA!\n",
      "6 Did that stop the old Grinch?\n",
      "7 On a ramshackle sleigh And he hitched up old Max. Then the Grinch said, \"Giddap!\" And the sleigh started down,\n",
      "8 He took the Whos' feast!\n",
      "9 She stared at the Grinch and said, \"Santy Claus, why,”\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "gen_summ = gensim.summarization.summarize(text, ratio=ratio)\n",
    "for i, sent in enumerate(gen_summ.split('\\n'), start=1):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PlaintextParser(text, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: The Grinch hated Christmas!>, <Sentence: And then!>, <Sentence: Then the Whos, young and old, would sit down to a feast.>, <Sentence: Then the Grinch, very nimbly, Stuffed all the bags, one by one, up the chimney!>, <Sentence: But, you know, that old Grinch was so smart and so slick, He thought up a lie, and he thought it up quick!>, <Sentence: And the one speck of food That he left in the house, Was a crumb that was even too small for a mouse.>, <Sentence: \"They're finding out now that no Christmas is coming!\">, <Sentence: \"They're just waking up!>, <Sentence: I know just what they'll do!\">, <Sentence: \"That's a noise,\" grinned the Grinch, \"That I simply MUST hear!\">, <Sentence: And the Grinch put his hand to his ear.>, <Sentence: It couldn't be so!>, <Sentence: But it WAS merry!>, <Sentence: And the Grinch, with his grinch-feet ice-cold in the snow, Stood puzzling and puzzling: \"How could it be so?\">, <Sentence: And the minute his heart didn't feel quite so tight, He whizzed with his load through the bright morning light, And he brought back the toys!>)\n"
     ]
    }
   ],
   "source": [
    "lex_rank = LexRankSummarizer()\n",
    "summ = lex_rank(parser.document, 15)\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: Whatever the reason, His heart or his shoes, He stood there on Christmas Eve, hating the Whos, Staring down from his cave with a sour, Grinchy frown, At the warm lighted windows below in their town.>, <Sentence: And the more the Grinch thought of this Who ChristmasSing, The more the Grinch thought, \"I must stop this whole thing!\">, <Sentence: Then he took some red thread, And he tied a big horn on the top of his head.>, <Sentence: And the sleigh started down, Toward the homes where the Whos Lay asnooze in their town.>, <Sentence: \"This is stop number one,\" the old Grinchy Claus hissed, And he climbed to the roof, empty bags in his fist.>, <Sentence: Then he slithered and slunk, with a smile most unpleasant, Around the whole room, and he took every present!>, <Sentence: Then the Grinch, very nimbly, Stuffed all the bags, one by one, up the chimney!>, <Sentence: And the Grinch grabbed the tree, and he started to shove, When he heard a small sound like the coo of a dove.>, <Sentence: But, you know, that old Grinch was so smart and so slick, He thought up a lie, and he thought it up quick!>, <Sentence: And when CindyLou Who went to bed with her cup, HE went to the chimney and stuffed the tree up!>, <Sentence: And the one speck of food That he left in the house, Was a crumb that was even too small for a mouse.>, <Sentence: Then He did the same thing To the other Whos' houses Leaving crumbs Much too small For the other Whos' mouses!>, <Sentence: It was quarter past dawn... All the Whos, still a-bed, All the Whos, still asnooze When he packed up his sled, Packed it up with their presents!>, <Sentence: And the Grinch, with his grinch-feet ice-cold in the snow, Stood puzzling and puzzling: \"How could it be so?\">, <Sentence: And the minute his heart didn't feel quite so tight, He whizzed with his load through the bright morning light, And he brought back the toys!>)\n"
     ]
    }
   ],
   "source": [
    "text_rank = TextRankSummarizer()\n",
    "summ = text_rank(parser.document, 15)\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
